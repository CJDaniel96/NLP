{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YelpCommentDatasetTrain.ipynb","provenance":[],"authorship_tag":"ABX9TyO9fI2ItuW7JGUCLFvbADSm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Xsoi2T4N3ZyX","executionInfo":{"status":"ok","timestamp":1626850894460,"user_tz":-480,"elapsed":273,"user":{"displayName":"蔡慶儒","photoUrl":"","userId":"16665259443696901662"}}},"source":["import torch\n","import torch as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","import pandas as pd"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQLJ0H5302hI","executionInfo":{"status":"ok","timestamp":1626850691862,"user_tz":-480,"elapsed":310,"user":{"displayName":"蔡慶儒","photoUrl":"","userId":"16665259443696901662"}}},"source":["def divide_data():\n","    by_rating = collections.defaultdict(list)\n","    for _, row in review_subset.iterrows():\n","        by_rating[row.rating].append(row.to_dict())\n","\n","    final_list = []\n","    np.random.seed(args.seed)\n","    for _, item_list in sorted(by_rating.items()):\n","        np.random.shuffle(item_list)\n","\n","        n_total = len(item_list)\n","        n_train = int(args.train_proportion * n_total)\n","        n_val = int(args.val_proportion * n_total)\n","        n_test = int(args.test_proportion * n_total)\n","\n","        for item in item_list[:n_train]:\n","            item['split'] = 'train'\n","        for item in item_list[n_train:n_train + n_val]:\n","            item['split'] = 'val'\n","        for item in item_list[n_train + n_val:n_train + n_val + n_test]:\n","            item['split'] = 'test'\n","        \n","        final_list.extand(item_list)\n","\n","    final_reviews = pd.DataFrame(final_list)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1mzcttk1ML-","executionInfo":{"status":"ok","timestamp":1626850819195,"user_tz":-480,"elapsed":716,"user":{"displayName":"蔡慶儒","photoUrl":"","userId":"16665259443696901662"}}},"source":["def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'([.,!?])', r'\\1', text)\n","    text = re.sub(r'[^a-zA-Z.,!?]+', r' ', text)\n","\n","    return text"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"utVJlGfG3XfW","executionInfo":{"status":"ok","timestamp":1626851605376,"user_tz":-480,"elapsed":385,"user":{"displayName":"蔡慶儒","photoUrl":"","userId":"16665259443696901662"}}},"source":["class ReviewDataset(Dataset):\n","    def __init__(self, review_df, vectorizer):\n","        self.review_df = review_df\n","        self._vectorizer = vectorizer\n","\n","        self.train_df = self.review_df[self.review_df.split == 'train']\n","        self.train_size = len(self.train_df)\n","\n","        self.val_df = self.review_df[self.review_df.split == 'val']\n","        self.val_size = len(self.val_df)\n","\n","        self.test_df = self.review_df[self.review_df.split == 'test']\n","        self.test_size = len(self.test_df)\n","\n","        self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                             'val': (self.val_df, self.val_size),\n","                             'test': (self.test_df, self.test_size)}\n","        self.set_split('train')\n","\n","    @classmethod\n","    def load_dataset_and_make_vectorizer(cls, review_csv):\n","        review_df = pd.read_csv(review_csv)\n","        \n","        return cls(review_df, ReviewVectorizer.from_dataframe(review_df))\n","\n","    def get_vectorizer(self):\n","        return self._vectorizer\n","\n","    def set_split(self, split='train'):\n","        self._tartget_split = split\n","        self._target_df, self._target_size = self._lookup_dict[split]\n","\n","    def __len__(self):\n","        return self._target_size\n","\n","    def __getitem__(self, index):\n","        row = self._target_df.iloc[index]\n","        review_vector = self._vectorizer.vectorize(row.review)\n","        rating_index = self._vectorizer.rating_vocab.lookup_token(row.rating)\n","\n","        return {'x_data': review_vector,\n","                'y_target': rating_index}\n","\n","    def get_num_batches(self, batch_size):\n","        return len(self) // batch_size"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IFegd_46Xgx"},"source":[""],"execution_count":null,"outputs":[]}]}